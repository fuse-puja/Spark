# Spark
---

# Exploring PySpark

## Introduction

PySpark is a powerful tool for data processing and analysis. This repository will help you understand Pyspark and Spark in step-by-step manner.

## Getting Started

1. **Installation**: Install Apache Spark and PySpark using `pip`.

2. **Setting Up PySpark**: Import PySpark and create a SparkSession in your Python script or Jupyter Notebook.

``from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("my_app").getOrCreate()``

---

# Dataset used
1. chipotle.csv
   - For Day_1 and Day_3 assignmnet
3. occupation.csv
   - For Day_2 assignmnet
5. Kalimati_tarkari_dataset.csv
   - For Day_3 assignmet
7. titatnic.csv
   - For Day_3 and Day_4 assignmnet
9. US_crime_rates_1960_2014.csv
    - For Day_4 assignment

All the dataset are stored in `data` directory
    
